# VideoLingo æµ‹è¯•æ¶æ„æŠ€æœ¯å®æ–½è¯¦ç»†æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£ä¸ºVideoLingoé¡¹ç›®æµ‹è¯•æ¶æ„é‡æ„æä¾›è¯¦ç»†çš„æŠ€æœ¯å®æ–½æŒ‡å¯¼ï¼ŒåŒ…å«å…·ä½“çš„ä»£ç ç¤ºä¾‹ã€é…ç½®æ–‡ä»¶ã€å·¥å…·ä½¿ç”¨æ–¹æ³•å’Œæ•…éšœæ’é™¤æ–¹æ¡ˆã€‚

## ğŸ—ï¸ åŸºç¡€è®¾æ–½å®æ–½

### 1. Mockç®¡ç†ç³»ç»Ÿå®ç°

#### 1.1 BaseMockåŸºç±»
```python
# tests/mocks/base_mock.py
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Union
from unittest.mock import patch, MagicMock
import logging
import time
import threading
from contextlib import contextmanager

class BaseMock(ABC):
    """ç»Ÿä¸€çš„MockåŸºç±»ï¼Œæä¾›ç”Ÿå‘½å‘¨æœŸç®¡ç†å’Œæ ‡å‡†æ¥å£"""
    
    def __init__(self, name: str):
        self.name = name
        self.is_active = False
        self.call_history: List[Dict[str, Any]] = []
        self.logger = logging.getLogger(f"mock.{name}")
        self._lock = threading.Lock()
        self.patches: List[patch] = []
        
    def __enter__(self):
        self.start()
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.stop()
        
    @abstractmethod
    def start(self) -> None:
        """å¯åŠ¨Mock"""
        if self.is_active:
            self.logger.warning(f"Mock {self.name} is already active")
            return
            
        self.is_active = True
        self.logger.info(f"Mock {self.name} started")
        
    @abstractmethod  
    def stop(self) -> None:
        """åœæ­¢Mock"""
        if not self.is_active:
            self.logger.warning(f"Mock {self.name} is not active")
            return
            
        for patch_obj in self.patches:
            try:
                patch_obj.stop()
            except Exception as e:
                self.logger.error(f"Error stopping patch: {e}")
                
        self.patches.clear()
        self.is_active = False
        self.logger.info(f"Mock {self.name} stopped")
        
    def record_call(self, method: str, args: tuple = (), kwargs: dict = None) -> None:
        """è®°å½•è°ƒç”¨å†å²"""
        with self._lock:
            self.call_history.append({
                'method': method,
                'args': args,
                'kwargs': kwargs or {},
                'timestamp': time.time()
            })
        self.logger.debug(f"Mock call recorded: {method}")
        
    def get_call_count(self, method: Optional[str] = None) -> int:
        """è·å–è°ƒç”¨æ¬¡æ•°"""
        with self._lock:
            if method is None:
                return len(self.call_history)
            return len([call for call in self.call_history if call['method'] == method])
            
    def clear_history(self) -> None:
        """æ¸…é™¤è°ƒç”¨å†å²"""
        with self._lock:
            self.call_history.clear()
        self.logger.debug(f"Mock {self.name} call history cleared")
        
    @contextmanager
    def temporary_response(self, method: str, response: Any):
        """ä¸´æ—¶è®¾ç½®ç‰¹å®šæ–¹æ³•çš„å“åº”"""
        original_response = getattr(self, f"_{method}_response", None)
        setattr(self, f"_{method}_response", response)
        try:
            yield
        finally:
            if original_response is not None:
                setattr(self, f"_{method}_response", original_response)
```

#### 1.2 APIæœåŠ¡Mockå®ç°
```python
# tests/mocks/api_service_mock.py
from typing import Dict, Any, Optional, List
from unittest.mock import patch, MagicMock, Mock
import json
import requests
from .base_mock import BaseMock

class APIServiceMock(BaseMock):
    """ç»Ÿä¸€çš„APIæœåŠ¡Mockç®¡ç†"""
    
    def __init__(self):
        super().__init__("api_service")
        self.response_templates = self._load_response_templates()
        self.error_conditions = {}
        self.latency_simulation = {}
        
    def _load_response_templates(self) -> Dict[str, Dict[str, Any]]:
        """åŠ è½½å“åº”æ¨¡æ¿"""
        return {
            'openai_chat_completion': {
                'id': 'chatcmpl-test',
                'object': 'chat.completion',
                'created': 1677652288,
                'model': 'gpt-3.5-turbo',
                'choices': [{
                    'index': 0,
                    'message': {
                        'role': 'assistant',
                        'content': 'This is a mocked response from OpenAI API.'
                    },
                    'finish_reason': 'stop'
                }],
                'usage': {
                    'prompt_tokens': 10,
                    'completion_tokens': 20,
                    'total_tokens': 30
                }
            },
            'azure_tts_success': {
                'status': 'success',
                'audio_data': b'mocked_audio_data_bytes',
                'content_type': 'audio/wav'
            },
            'elevenlabs_tts_success': {
                'audio': b'mocked_elevenlabs_audio',
                'history_item_id': 'mock_history_id'
            },
            'whisperx_transcription': {
                'text': 'This is a mocked transcription result.',
                'segments': [{
                    'start': 0.0,
                    'end': 5.0,
                    'text': 'This is a mocked transcription result.',
                    'words': [
                        {'start': 0.0, 'end': 0.5, 'word': 'This'},
                        {'start': 0.5, 'end': 1.0, 'word': 'is'},
                        {'start': 1.0, 'end': 1.2, 'word': 'a'},
                        {'start': 1.2, 'end': 1.8, 'word': 'mocked'},
                        {'start': 1.8, 'end': 2.5, 'word': 'transcription'},
                        {'start': 2.5, 'end': 3.0, 'word': 'result.'}
                    ]
                }],
                'language': 'en'
            }
        }
        
    def start(self) -> None:
        """å¯åŠ¨æ‰€æœ‰API Mock"""
        super().start()
        
        # Mock OpenAI API
        self._setup_openai_mock()
        
        # Mock Azure TTS API
        self._setup_azure_mock()
        
        # Mock ElevenLabs API
        self._setup_elevenlabs_mock()
        
        # Mock WhisperX API
        self._setup_whisperx_mock()
        
        # Mock requests.post for general HTTP calls
        self._setup_requests_mock()
        
    def _setup_openai_mock(self) -> None:
        """è®¾ç½®OpenAI API Mock"""
        openai_patch = patch('openai.OpenAI')
        mock_openai_client = openai_patch.start()
        
        # Mock chat completion
        mock_completion = MagicMock()
        mock_completion.create.return_value = MagicMock(
            **self.response_templates['openai_chat_completion']
        )
        mock_openai_client.return_value.chat.completions = mock_completion
        
        # è®°å½•è°ƒç”¨
        original_create = mock_completion.create
        def create_with_recording(*args, **kwargs):
            self.record_call('openai_chat_completion', args, kwargs)
            return original_create(*args, **kwargs)
        mock_completion.create = create_with_recording
        
        self.patches.append(openai_patch)
```

### 2. æµ‹è¯•æ•°æ®ç®¡ç†ç³»ç»Ÿ

#### 2.1 Fixtureç®¡ç†å™¨
```python
# tests/fixtures/__init__.py
import json
import yaml
import os
from pathlib import Path
from typing import Dict, Any, List, Optional, Union
import tempfile
import shutil
from contextlib import contextmanager

class TestDataManager:
    """æµ‹è¯•æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self, data_dir: Optional[Path] = None):
        self.data_dir = data_dir or Path(__file__).parent / "data"
        self.data_dir.mkdir(exist_ok=True)
        self._cache: Dict[str, Any] = {}
        self.temp_dirs: List[Path] = []
        
    def load_fixture(self, name: str, format: str = 'json') -> Union[Dict[str, Any], List, str]:
        """åŠ è½½æµ‹è¯•fixture"""
        cache_key = f"{name}.{format}"
        
        if cache_key in self._cache:
            return self._cache[cache_key]
            
        fixture_path = self.data_dir / f"{name}.{format}"
        if not fixture_path.exists():
            raise FileNotFoundError(f"Fixture not found: {fixture_path}")
            
        with open(fixture_path, 'r', encoding='utf-8') as f:
            if format == 'json':
                data = json.load(f)
            elif format == 'yaml' or format == 'yml':
                data = yaml.safe_load(f)
            else:
                data = f.read()
                
        self._cache[cache_key] = data
        return data
        
    def get_sample_config(self, profile: str = 'default') -> Dict[str, Any]:
        """è·å–ç¤ºä¾‹é…ç½®"""
        configs = {
            'default': {
                'api': {
                    'key': 'test_api_key_default',
                    'base_url': 'https://api.test.com',
                    'model': 'test-model'
                },
                'video': {
                    'max_duration': 600,
                    'quality': 'best',
                    'format': 'mp4'
                }
            }
        }
        
        return configs.get(profile, configs['default'])

# å…¨å±€æµ‹è¯•æ•°æ®ç®¡ç†å™¨å®ä¾‹
test_data = TestDataManager()
```

### 3. pytesté…ç½®ä¼˜åŒ–

#### 3.1 é«˜æ€§èƒ½pytest.inié…ç½®
```ini
# tests/pytest.ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

addopts = 
    --verbose
    --tb=short
    --strict-markers
    --maxfail=10
    --cov=core
    --cov-report=html:tests/reports/coverage_html
    --cov-report=xml:tests/reports/coverage.xml
    --cov-report=term-missing:skip-covered
    --cov-fail-under=60
    --durations=10

# å¹¶å‘æ‰§è¡Œ
addopts = -n auto

markers =
    unit: å•å…ƒæµ‹è¯•
    component: ç»„ä»¶æµ‹è¯•
    integration: é›†æˆæµ‹è¯•
    e2e: ç«¯åˆ°ç«¯æµ‹è¯•
    slow: æ…¢é€Ÿæµ‹è¯•
    fast: å¿«é€Ÿæµ‹è¯•

filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

timeout = 300
timeout_method = thread

log_cli = false
log_cli_level = INFO
```

## ğŸ”§ æ•…éšœæ’é™¤æŒ‡å—

### å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ

#### 1. æµ‹è¯•æ‰§è¡Œé—®é¢˜

**é—®é¢˜**: æµ‹è¯•æ— æ³•è¿è¡Œï¼Œæç¤ºå¯¼å…¥é”™è¯¯
```bash
ImportError: No module named 'core'
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# åœ¨conftest.pyä¸­æ·»åŠ è·¯å¾„è®¾ç½®
import sys
from pathlib import Path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
```

#### 2. è¦†ç›–ç‡é—®é¢˜

**é—®é¢˜**: è¦†ç›–ç‡æŠ¥å‘Šä¸å‡†ç¡®æˆ–ç¼ºå¤±
```bash
coverage report
# No data to report
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥è¦†ç›–ç‡é…ç½®
pytest --cov=core --cov-report=term-missing tests/
```

### æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### 1. å¹¶è¡Œæµ‹è¯•æ‰§è¡Œ
```bash
# å®‰è£…pytest-xdist
pip install pytest-xdist

# è‡ªåŠ¨æ£€æµ‹CPUæ ¸å¿ƒæ•°
pytest -n auto
```

---

*æœ¬æŠ€æœ¯å®æ–½æŒ‡å—æä¾›äº†VideoLingoé¡¹ç›®æµ‹è¯•æ¶æ„é‡æ„çš„è¯¦ç»†æŠ€æœ¯ç»†èŠ‚å’Œæœ€ä½³å®è·µã€‚*